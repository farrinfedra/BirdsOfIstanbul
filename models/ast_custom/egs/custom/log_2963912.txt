+ export TORCH_HOME=../../pretrained_models
+ TORCH_HOME=../../pretrained_models
+ model=ast
+ dataset=custom
+ nocall=True
+ timetest = True
/var/spool/slurm/d/job2963912/slurm_script: line 24: timetest: command not found
+ imagenetpretrain=True
+ audiosetpretrain=True
+ bal=True
+ '[' True == True ']'
+ lr=1e-5
+ freqm=24
+ timem=96
+ mixup=0
+ epoch=6
+ batch_size=48
+ fstride=10
+ tstride=10
+ base_exp_dir=./exp/train-custom-f10-t10-impTrue-aspTrue-b48-lr1e-5-6-istangull_ncd_sm
+ '[' -d ./exp/train-custom-f10-t10-impTrue-aspTrue-b48-lr1e-5-6-istangull_ncd_sm ']'
+ mkdir -p
mkdir: missing operand
Try 'mkdir --help' for more information.
+ (( fold=1 ))
+ (( fold<=5 ))
+ echo 'now process fold1'
now process fold1
+ exp_dir=./exp/train-custom-f10-t10-impTrue-aspTrue-b48-lr1e-5-6-istangull_ncd_sm/fold1
+ tr_data=./data/datafiles/custom_train_data_1.json
+ te_data=./data/datafiles/custom_eval_data_1.json
+ CUDA_CACHE_DISABLE=1
+ python -W ignore ../../src/run.py --model ast --dataset custom --data-train ./data/datafiles/custom_train_data_1.json --data-val ./data/datafiles/custom_eval_data_1.json --exp-dir ./exp/train-custom-f10-t10-impTrue-aspTrue-b48-lr1e-5-6-istangull_ncd_sm/fold1 --label-csv ./data/custom_labels.csv --n_class 21 --lr 1e-5 --n-epochs 6 --batch-size 48 --save_model False --freqm 24 --timem 96 --mixup 0 --bal True --tstride 10 --fstride 10 --imagenet_pretrain True --audioset_pretrain True
wandb: Currently logged in as: birdsongs (use `wandb login --relogin` to force relogin)
I am process 123695, running on ai10.kuacc.ku.edu.tr: starting (Mon Apr 18 19:42:18 2022)
wandb: Tracking run with wandb version 0.12.9
wandb: Syncing run ancient-star-25
wandb:  View project at https://wandb.ai/birdsongs/istangul-sm-dataset
wandb:  View run at https://wandb.ai/birdsongs/istangul-sm-dataset/runs/3biu2eza
wandb: Run data is saved locally in /scratch/users/fsofian19/COMP491_model/models/ast_custom/egs/custom/wandb/run-20220418_194219-3biu2eza
wandb: Run `wandb offline` to turn off syncing.

now train a audio spectrogram transformer model
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 24 freq, 96 time
now using mix-up with rate 0.000000
now process custom
use dataset mean -5.519 and std 4.572 to normalize the input.
number of classes is 21
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process custom
use dataset mean -5.519 and std 4.572 to normalize the input.
number of classes is 21
---------------AST Model Summary---------------
ImageNet pretraining: True, AudioSet pretraining: True
frequncey stride=10, time stride=10
number of patches=600

Creating experiment directory: ./exp/train-custom-f10-t10-impTrue-aspTrue-b48-lr1e-5-6-istangull_ncd_sm/fold1
Now starting training for 6 epochs
2022-04-18 19:42:44.724342
running on cuda
state dict to model completed => pretrained weights loaded
Total parameter number is : 87.273 million
Total trainable parameter number is : 87.273 million
scheduler for custom dataset is used
now training with custom, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f09b8409b20>
current #steps=0, #epochs=1
start training...
---------------
2022-04-18 19:42:45.170540
current #epochs=1, #steps=0
