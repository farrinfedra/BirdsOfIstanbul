{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d1ad9a-909c-44f2-807e-74af01a442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38853205-8b82-4831-bdf1-df4a54cc56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ASTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7cb46a-ed5d-4116-b9ec-584cd825e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6276f87-d760-4760-99d7-af9e5cafebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=600\n"
     ]
    }
   ],
   "source": [
    "audio_model = ASTModel(label_dim=50, fstride=10, tstride=10, input_fdim=128,\n",
    "                                  input_tdim=512, imagenet_pretrain=True,\n",
    "                                  audioset_pretrain=True, model_size='base384')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "path = '/kuacc/users/fsofian19/COMP491_model/models/ssast_istangul/src/finetune/custom/exp/train01-custom-b16-lr1e-4-ft_avgtok-base-1x-noiseTrue-50class/models/audio_model.7.pth'\n",
    "\n",
    "sd = torch.load(path, map_location=device)\n",
    "\n",
    "if not isinstance(audio_model, nn.DataParallel):\n",
    "    audio_model = nn.DataParallel(audio_model)\n",
    "audio_model = audio_model.to(device)\n",
    "audio_model.load_state_dict(sd,strict=False)\n",
    "\n",
    "audio_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e24882a-acf9-4247-9c6a-b24529ded657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbank(filename):\n",
    "        # mixup\n",
    "\n",
    "        waveform, sr = torchaudio.load(filename)\n",
    "        waveform = waveform - waveform.mean()\n",
    "\n",
    "\n",
    "        fbank = torchaudio.compliance.kaldi.fbank(waveform, htk_compat=True, sample_frequency=sr, use_energy=False,\n",
    "                                                  window_type='hanning', num_mel_bins=128, dither=0.0, frame_shift=10)\n",
    "\n",
    "        target_length = 512\n",
    "        n_frames = fbank.shape[0]\n",
    "\n",
    "        p = target_length - n_frames\n",
    "\n",
    "        # cut and pad\n",
    "        if p > 0:\n",
    "            m = torch.nn.ZeroPad2d((0, 0, 0, p))\n",
    "            fbank = m(fbank)\n",
    "        elif p < 0:\n",
    "            fbank = fbank[0:target_length, :]\n",
    "\n",
    "\n",
    "        return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236afc9-8d23-4bef-80eb-cf851a50358c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "869ea1a6-2e50-4a77-8c70-42b6a411497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3119, 0.1915, 0.2662, 0.1010, 0.2327, 0.4213, 0.1695, 0.3143, 0.1613,\n",
       "         0.1568, 0.3740, 0.3630, 0.2916, 0.4650, 0.3148, 0.3887, 0.2310, 0.2693,\n",
       "         0.7696, 0.2022, 0.2180]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_fbank = get_fbank('/kuacc/users/bbiner21/birdclef-2022/birdclef-2022-16khz/skylar/XC362045.ogg')\n",
    "\n",
    "#/kuacc/users/bbiner21/birdclef-2022/birdclef-2022-16khz/akiapo/XC122401.ogg\n",
    "#/kuacc/users/bbiner21/ast/egs/custom/data/custom_data/audio_16k/XC109605.ogg\n",
    "# plt.figure()\n",
    "# cur_fbank = torch.flip(cur_fbank.t(), [0])\n",
    "# plt.imshow(cur_fbank.numpy(), cmap='gray',aspect='auto')\n",
    "print(cur_fbank.shape)\n",
    "\n",
    "norm_mean = -6.0138397\n",
    "norm_std = 4.589279\n",
    "\n",
    "cur_fbank = (cur_fbank - norm_mean) / (norm_std * 2)\n",
    "\n",
    "cur_fbank = cur_fbank.unsqueeze(0)\n",
    "out = audio_model(cur_fbank)\n",
    "out = torch.sigmoid(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07268ea2-ac22-4e4c-912b-9895877e6dd0",
   "metadata": {},
   "source": [
    "acafly not related outcome:\n",
    "    \n",
    "    torch.Size([512, 128])\n",
    "tensor([[0.1974, 0.2464, 0.2258, 0.3338, 0.4712, 0.3498, 0.3351, 0.4172, 0.5377,\n",
    "         0.5493, 0.3549, 0.2314, 0.3850, 0.2837, 0.3573, 0.3430, 0.3483, 0.4577,\n",
    "         0.3570, 0.2635, 0.4420]], grad_fn=<SigmoidBackward>)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08144e92-a877-4dd2-9ecf-4f19612b1554",
   "metadata": {},
   "source": [
    "torch.Size([512, 128])\n",
    "tensor([[0.2151, 0.2638, 0.4018, 0.2365, 0.3195, 0.3828, 0.2911, 0.4171, 0.4522,\n",
    "         0.3644, 0.3285, 0.2688, 0.4032, 0.2361, 0.3715, 0.3445, 0.3226, 0.4550,\n",
    "         0.3284, 0.2933, 0.4129]], grad_fn=<SigmoidBackward>)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f116daaa-b4f4-4cc2-a4ce-11354d19eb54",
   "metadata": {},
   "source": [
    "3 model\n",
    "\n",
    "torch.Size([512, 128])\n",
    "tensor([[0.3255, 0.2855, 0.4259, 0.2589, 0.3739, 0.3689, 0.4024, 0.4929, 0.5167,\n",
    "         0.3454, 0.3266, 0.2860, 0.4588, 0.2650, 0.3387, 0.3065, 0.2211, 0.5293,\n",
    "         0.3875, 0.2309, 0.4036]], grad_fn=<SigmoidBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3286cb4e-6553-4e7e-bf3a-55e1bcbfec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f883aada-20fb-4d5a-aa87-c62c6d4a3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.zeros(1,21)\n",
    "temp[0,18] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff085b7b-dd34-4cc7-b52f-3a83cd8a904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4b72b43-2ca3-46e5-b772-7244232934de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = calculate_stats(out.detach(),temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
